# MaskMixAdv: Scribble-supervised Medical Image Segmentation via MaskMix-based Siamese Network and Shape-aware Adversarial Learning
1) MaskMixAdv for the first time designs a Mask-based Mixup strategy (MaskMix) for scribble-supervised medical image segmentation. MaskMix introduces image-level and feature-level perturbations to one sample for data augmentation, replacing the graphical-based or the traditional cross-sample mixup approaches.

2) MaskMixAdv for the first time designs a dual-branches siamese network, trained by segmentation and reconstruction in different branches based on the MaskMix strategy. Pseudo labels are generated by integrating the two-branch prediction results through complementary binary masks, which can further boost 3D Dice.

3) MaskMixAdv learns to regularize the generated pseudo labels via shape-aware adversarial learning to incorporate additional shape priors, which can reduce the Hausdorff distance.

<p align="center"><img width="100%" src="imgs/framework5.png" /></p>

In this repository we release multiple models from our paper.  


## Major results from our work
1. **The proposed MaskMixAdv achieved the best performance among all self-supervised learning methods and ImageNet-based supervised SOTA methods on all tasks. Results demonstrated the performance superiority and robustness of our work. Therefore, MaskMixAdv provided a more promising preferred initialization alternative for most medical image analysis tasks, especially those without annotations.**

<p align="center"><img width="100%" src="imgs/compare_result.png" /></p>


2. **Contrastive learning with generative proxy tasks outperformed traditional ones ($\mathcal L_{Con}^{NL+M}>\mathcal L_{Con}^{*}$), demonstrating the effectiveness of generative proxy tasks in improving contrastive learning. 
Results demonstrated that our work unlocked the power of contrastive learning in medical image analysis. The whole framework achieved the best performance and convergence after synergizing contrastive and generative learning ($\mathcal L_{Con}^{NL+M}$+$\mathcal L_{Gen}^{NL+M}>\mathcal L_{Con}^{NL+M}$ and $>\mathcal L_{Gen}^{NL+M}$), demonstrating the effectiveness of cooperation between generative and contrastive learning.**

<p align="center"><img width="100%" src="imgs/ablation_result.png" /></p>


3. **MaskMixAdv can mitigate the lack of annotations, resulting in a more label-efficient deep learning in medical image analysis. MaskMixAdv can be fine-tuned on a few labeled datasets to achieve comparable performance to the full-labeled dataset.**

<p align="center"><img width="100%" src="imgs/result1.png" /></p>


## Packages Installation
Clone the repository and install dependencies using the following command:
```bash
$ cd MaskMixAdv
$ pip install -r requirements.txt
```

## Model Implementation
In this paper, we evaluate 19 pre-trained ResNet50 models, including: 1 supervised ImageNet model, 17 self-supervised models, and our proposed model. To download and prepare all models in the same format, run:


# Dataset
Datasets and more details can be found from the following links. 
* The ACDC dataset with mask annotations can be downloaded from: [ACDC](https://www.creatis.insa-lyon.fr/Challenge/acdc/databases.html).
* The Scribble annotations of ACDC can be downloaded from: [Scribble](https://gvalvano.github.io/wss-multiscale-adversarial-attention-gates/data).
* The data processing code in [Here](https://github.com/Luoxd1996/WSL4MIS/blob/main/code/dataloaders/acdc_data_processing.py)  the pre-processed ACDC data in [Here](https://github.com/HiLab-git/WSL4MIS/tree/main/data/ACDC).
* The MSCMR dataset with mask annotations can be downloaded from [MSCMRseg](https://zmiclab.github.io/zxh/0/mscmrseg19/data.html).
* Please organize the dataset as the following structure:
```
ACDC/
  -- ACDC_training_slices/
      --patient001_frame01_slice_0.h5
      ...
  -- ACDC_training_volumes/
      --patient001_frame01.h5
      ...
```


## Models pre-training
1. Download the desired dataset or you can simply add any other dataset that you wish. Save them to `./data` directory.
2. Run:

# Usage

1. Clone this project.
```
git clone ***************
cd MaskMixAdv
```
2. Data pre-processing os used or the processed data.
```
cd code
python dataloaders/acdc_data_processing.py
```
3. Train the model
```
cd code
./train_wss.sh
```

4. Test the model
```
python test_2D_fully.py --sup_type scribble/label --exp ACDC/the trained model fold --model unet
```

5. Training curves on the fold1:

**Note**: pCE means partially cross-entropy, TV means total variation, label denotes supervised by mask, scribble represents just supervised by scribbles.

# Implemented methods
* [**pCE**](https://openaccess.thecvf.com/content_cvpr_2018/papers/Tang_Normalized_Cut_Loss_CVPR_2018_paper.pdf)
* [**pCE + TV**](https://arxiv.org/pdf/1605.01368.pdf)
* [**pCE + Entropy Minimization**](https://arxiv.org/pdf/2111.02403.pdf)
* [**pCE + GatedCRFLoss**](https://github.com/LEONOB2014/GatedCRFLoss)
* [**pCE + Intensity Variance Minimization**](https://arxiv.org/pdf/2111.02403.pdf)
* [**pCE + Random Walker**](http://vision.cse.psu.edu/people/chenpingY/paper/grady2006random.pdf)
* [**pCE + MumfordShah_Loss**](https://arxiv.org/pdf/1904.02872.pdf)
* [**Scribble2Label**](https://arxiv.org/pdf/2006.12890.pdf)
* [**USTM**](https://www.sciencedirect.com/science/article/pii/S0031320321005215)
* [**WSL4MIS**](https://github.com/Luoxd1996/WSL4MIS)


## Acknowledgement
Anonymous
## Reference
Anonymous
## License
Anonymous

#### ** We hope that in the light of our study, the medical imaging and computer vision community will benefit from the use of more powerful weakly-supervised models. **